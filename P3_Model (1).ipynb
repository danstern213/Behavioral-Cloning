{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, Cropping2D\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_names = ['center', 'left', 'right', 'steering']\n",
    "dataframe = pd.read_csv('./data/driving_log.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import center images, resize and crop\n",
    "\n",
    "center_images = []\n",
    "center = dataframe.center.tolist()\n",
    "for i in center:\n",
    "    image = mpimg.imread('./data/' + i)\n",
    "    image = cv2.resize(image, (200, 66))\n",
    "    image = image[20:66, :200]\n",
    "    center_images.append(image)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put into a numpy array\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "center_images = np.asarray(center_images)\n",
    "\n",
    "plt.imshow(center_images[5])\n",
    "center_images[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import left images and resize and crop\n",
    "\n",
    "left_images = []\n",
    "left = dataframe.left.tolist()\n",
    "\n",
    "lefty = [i.strip() for i in left]\n",
    "\n",
    "for i in lefty:\n",
    "    image = mpimg.imread('./data/' + i)\n",
    "    image = cv2.resize(image, (200, 66))\n",
    "    image = image[20:66, :200]\n",
    "    left_images.append(image)\n",
    "\n",
    "left_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_images = np.asarray(left_images)\n",
    "\n",
    "plt.imshow(left_images[5])\n",
    "left_images[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import right images, resize and crop\n",
    "\n",
    "right_images = []\n",
    "right = dataframe.right.tolist()\n",
    "\n",
    "righty = [i.strip() for i in right]\n",
    "\n",
    "for i in righty:\n",
    "    image = mpimg.imread('./data/' + i)\n",
    "    image = cv2.resize(image, (200, 66))\n",
    "    image = image[20:66, :200]\n",
    "    right_images.append(image)\n",
    "\n",
    "right_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "right_images = np.asarray(right_images)\n",
    "\n",
    "plt.imshow(right_images[5])\n",
    "right_images[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add in steering values \n",
    "\n",
    "center_values = []\n",
    "for i in dataframe['steering']:\n",
    "    center_values.append(i)\n",
    "\n",
    "center_values = np.asarray(center_values)\n",
    "len(center_values)\n",
    "steering = dataframe.steering.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "with open('./allimages.p', 'wb') as f:\n",
    "    data = pickle.dump(center_images, left_images, right_images, f)\n",
    "    labels = pickle.dump(center_values, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "with open('./allimages.p', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split up data and shuffle\n",
    "\n",
    "X_train, x_validation, y_train, y_validation = train_test_split(center_images, center_values, test_size = 0.2)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Split up steering angle turns for center images\n",
    "\n",
    "straight, left, right = [], [], []\n",
    "steer_straight, steer_left, steer_right = [], [], []\n",
    "\n",
    "index = 0\n",
    "for i in steering:\n",
    "    \n",
    "    if i > 0.15:\n",
    "        right.append(center_images[index])\n",
    "        steer_right.append(i)\n",
    "        index += 1\n",
    "    elif i < -0.15:\n",
    "        left.append(center_images[index])\n",
    "        steer_left.append(i)\n",
    "        index += 1\n",
    "    else:\n",
    "        straight.append(center_images[index])\n",
    "        steer_straight.append(i)\n",
    "        index +=1 \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6541 6541\n",
      "902 902\n",
      "593 593\n"
     ]
    }
   ],
   "source": [
    "print(len(straight), len(steer_straight))\n",
    "print(len(right), len(steer_right))\n",
    "print(len(left), len(steer_left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1804 1804\n"
     ]
    }
   ],
   "source": [
    "# adjust steering angle values for left images\n",
    "\n",
    "for i in range(len(left_images)):\n",
    "    if steering[i] > 0.15:\n",
    "        right.append(left_images[i])\n",
    "        steer_right.append(steering[i] + 0.25)\n",
    "        \n",
    "print(len(steer_right), len(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1186 1186\n"
     ]
    }
   ],
   "source": [
    "# adjust steering angle values for right images\n",
    "\n",
    "for i in range(len(right_images)):\n",
    "    if steering[i] < -0.15:\n",
    "        left.append(right_images[i])\n",
    "        steer_left.append(steering[i] + -0.25)\n",
    "\n",
    "print(len(steer_left), len(left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert back to a single numpy array\n",
    "\n",
    "X_train = np.float32(straight + left + right)\n",
    "y_train = np.float32(steer_straight + steer_left + steer_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9531 samples, validate on 1608 samples\n",
      "Epoch 1/5\n",
      "72s - loss: 0.0224 - val_loss: 0.0085\n",
      "Epoch 2/5\n",
      "70s - loss: 0.0121 - val_loss: 0.0076\n",
      "Epoch 3/5\n",
      "65s - loss: 0.0114 - val_loss: 0.0074\n",
      "Epoch 4/5\n",
      "67s - loss: 0.0105 - val_loss: 0.0070\n",
      "Epoch 5/5\n",
      "75s - loss: 0.0099 - val_loss: 0.0068\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_2 (Lambda)                (None, 46, 200, 3)    0           lambda_input_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 21, 98, 24)    1824        lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 21, 98, 24)    0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 21, 98, 24)    0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 9, 47, 36)     21636       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 9, 47, 36)     0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 9, 47, 36)     0           activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 3, 22, 48)     43248       dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 3, 22, 48)     0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 1, 20, 64)     27712       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 1, 20, 64)     0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 1280)          0           activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 100)           128100      flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 100)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 100)           0           activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 50)            5050        dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 50)            0           dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 50)            0           activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 10)            510         dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 10)            0           dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1)             11          activation_14[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 228,091\n",
      "Trainable params: 228,091\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kernal = [5, 5]\n",
    "kernal2 = [3, 3]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(lambda x: x/127.5 - 1., input_shape=(46, 200, 3)))\n",
    "\n",
    "model.add(Convolution2D(24, kernal[0], kernal[1], subsample=(2,2), input_shape=(46, 200, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Convolution2D(36, kernal[0], kernal[1], subsample=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Convolution2D(48, kernal[0], kernal[1], subsample=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(64, kernal2[0], kernal2[1], subsample=(1,1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Convolution2D(64, kernal2[0], kernal2[1], subsample=(1,1)))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "#optimizer, loss, accuracy\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "#train the model\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=epochs, verbose=2, validation_data=(x_validation, y_validation))\n",
    "\n",
    "#evaluate the accuracy of the model\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./model.json', 'w') as outfile:\n",
    "    json.dump(model.to_json(), outfile)\n",
    "\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
